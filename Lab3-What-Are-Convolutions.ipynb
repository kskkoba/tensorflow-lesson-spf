{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/lmoroney/mlday-tokyo/blob/master/Lab3-What-Are-Convolutions.ipynb","timestamp":1589364975498}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"GhZOHbwJOvio"},"source":["##What are Convolutions?\n","\n","ここでは、コンボリューションを使用してコンピュータビジョンを強化する方法を探ります。しかし、コンボリューションとは何でしょうか？ここでは、コンボリューションとは何か、どのように動作するのかを探求し、つぎの章では、ニューラルネットワークでの使用方法を見ていきます。"]},{"cell_type":"markdown","metadata":{"id":"nidI4HtcVQ7i"},"source":["\n","\n","畳み込みと一緒に、画像を圧縮して特徴をさらに強調する「プーリング」と呼ばれるものを使用します。ここでは、プーリングがどのように機能するかも見てみましょう。"]},{"cell_type":"markdown","metadata":{"id":"DdBFQswdO-kX"},"source":["##Limitations of the previous DNN\n","\n","\n","前回のラボでは、Fashion MNISTデータセットを用いてファッションアイテムの画像分類器を訓練する方法を見ました。これでかなり正確な分類器が得られましたが、明らかな制約がありました：画像は28x28、グレースケールで、アイテムは画像の中心にあることです。\n","\n","例えば、以下はFashion MNISTの画像の一部です。\n","![セーターとブーツの写真](https://cdn-images-1.medium.com/max/1600/1*FekMt6abfFFAFzhQcnjxZg.png)\n","\n","あなたが作成したDNNは、単に生のピクセルからセーターを構成するものと、ブーツを構成するものを学習しました。しかし、この画像をどのように分類するか考えてみましょう。\n","\n","![ブーツの画像](https://cdn.pixabay.com/photo/2013/09/12/19/57/boots-181744_1280.jpg)\n","\n","この画像にブーツがあることは明らかですが、分類器はいくつかの理由で失敗します。第一に、もちろん、これは28x28のグレースケールではありません。より重要なことは、分類器は左向きのブーツの画像で訓練されており、ブーツが何であるかということで訓練されていないということです。\n","\n","そこでコンボリューションが非常に強力なのです。畳み込みとは、画像を処理し、画像の共通性を示す特徴を抽出するフィルタです。このラボでは、コンボリューションがどのように動作するかを見ますが、画像を処理して、画像から特徴を抽出できるかどうかを見てみましょう!\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ds0NF5KFVmG2"},"source":["\n","\n","畳み込みを実行するのはとても単純です。単純に画像の各画素をスキャンして、その画素に隣接する画素を見るだけです。そしてこれらのピクセルの値にフィルタの等価な重みを掛け合わせます。\n","\n","例えば次のように考えてみてください。\n","\n","![画像上のコンボリューション](https://storage.googleapis.com/laurencemoroney-blog.appspot.com/MLColabImages/lab3-fig1.png)\n","\n","![](https://techblog.gmo-ap.jp/wp-content/uploads/2019/04/3D_Convolution_Animation.gif)\n","\n","この場合は 3x3 コンボリューションが指定されています。\n","\n","現在の画素の値は 192 ですが、隣接する画素の値を見てフィルタで指定した値を掛け合わせて新しい画素の値を計算し、その値を最終的な値とします。"]},{"cell_type":"markdown","metadata":{"id":"tJTHvE8Qe5nM"},"source":["\n","2Dのグレースケール画像に基本的な畳み込みを作成することで、畳み込みがどのように機能するかを探ってみましょう。まず、scipyの'asccent'画像を使って画像をロードします。これは、角度や線がたくさん入った素敵な組み込み画像です。"]},{"cell_type":"markdown","metadata":{"id":"KTS2sc5nQSCJ"},"source":["\n","まずは、Pythonのライブラリをインポートしてみましょう。"]},{"cell_type":"code","metadata":{"id":"DZ5OXYiolCUi"},"source":["import cv2\n","import numpy as np\n","from scipy import misc\n","i = misc.ascent()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SRIzxjWWfJjk"},"source":["次に、pyplotライブラリを使って画像を描画することで、どのように見えるか確認しましょう。"]},{"cell_type":"code","metadata":{"id":"R4p0cfWcfIvi"},"source":["import matplotlib.pyplot as plt\n","plt.grid(False)\n","plt.gray()\n","plt.axis('off')\n","plt.imshow(i)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C1mhZ_ZTfPWH"},"source":["これは階段の吹き抜けのイメージであることがわかります。ここにはたくさんの特徴があるので、それらを分離できるかどうかを試すことができます -- 例えば、強い垂直線があります。\n","\n","画像は numpy 配列として保存されているので、その配列をコピーするだけで変換された画像を作ることができます。画像の次元も取得しておきましょう。"]},{"cell_type":"code","metadata":{"id":"o5pxGq1SmJMD"},"source":["i_transformed = np.copy(i)\n","size_x = i_transformed.shape[0]\n","size_y = i_transformed.shape[1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y7PwNkiXfddd"},"source":["これでフィルタを 3x3 の配列として作成できるようになりました。"]},{"cell_type":"code","metadata":{"id":"sN3imZannN5J"},"source":["# This filter detects edges nicely\n","# It creates a convolution that only passes through sharp edges and straight\n","# lines.\n","\n","#Experiment with different values for fun effects.\n","#filter = [ [0, 1, 0], [1, -4, 1], [0, 1, 0]]\n","\n","# A couple more filters to try for fun!\n","filter = [ [-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n","#filter = [ [-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n","\n","#filter = [ [0, -1, 0], [-1, 5, -1], [0, -1, 0]]\n","\n","\n","# 下のセルで垂直線強調としているフィルタ例\n","#filter = [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n","# 下のセルで水平線強調としているフィルタ例\n","#filter = [[-1, -2, -1], [0, 0, 0], [1, 2, 1 ]]\n","\n","# If all the digits in the filter don't add up to 0 or 1, you \n","# should probably do a weight to get it to do so\n","# so, for example, if your weights are 1,1,1 1,2,1 1,1,1\n","# They add up to 10, so you would set a weight of .1 if you want to normalize them\n","weight  = 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JQmm_iBufmCz"},"source":["ここで畳み込みを作成してみましょう。1 ピクセルの余白を残して画像を繰り返し処理し、 現在の画素の隣り合う画素にフィルターで定義された値をかけます。（小林注：3x3のフィルタをパディングをあてずに畳み込みをすることを言っています）\n","\n","つまり、 現在の画素のその上と左隣の画素にはフィルターの左上の項目が掛けられます。そしてその結果に重みをかけて 0 から 255 の範囲内に収まるようにします。\n","\n","最後に、変換された画像に新しい値を読み込みます。"]},{"cell_type":"code","metadata":{"id":"299uU2jAr90h"},"source":["for x in range(1,size_x-1):\n","  for y in range(1,size_y-1):\n","      convolution = 0.0\n","      convolution = convolution + (i[x - 1, y-1] * filter[0][0])\n","      convolution = convolution + (i[x, y-1] * filter[0][1])\n","      convolution = convolution + (i[x + 1, y-1] * filter[0][2])\n","      convolution = convolution + (i[x-1, y] * filter[1][0])\n","      convolution = convolution + (i[x, y] * filter[1][1])\n","      convolution = convolution + (i[x+1, y] * filter[1][2])\n","      convolution = convolution + (i[x-1, y+1] * filter[2][0])\n","      convolution = convolution + (i[x, y+1] * filter[2][1])\n","      convolution = convolution + (i[x+1, y+1] * filter[2][2])\n","      convolution = convolution * weight\n","      if(convolution<0):\n","        convolution=0\n","      if(convolution>255):\n","        convolution=255\n","      i_transformed[x, y] = convolution"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6XA--vgvgDEQ"},"source":["これで、画像をプロットして畳み込みの効果を確認することができます!"]},{"cell_type":"code","metadata":{"id":"7oPhUPNhuGWC"},"source":["# Plot the image. Note the size of the axes -- they are 512 by 512\n","plt.gray()\n","plt.grid(False)\n","plt.imshow(i_transformed)\n","#plt.axis('off')\n","plt.show()   "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Df7kw1m6XDwz"},"source":["そこで以下のフィルタの値とその画像への影響を考えてみましょう。\n","\n","-1, 0, 1, -2, 0, 2, -1, 0, 1 を使うと非常に強い垂直線の集合が得られます。\n","\n","![Detecting vertical lines filter](https://storage.googleapis.com/laurencemoroney-blog.appspot.com/MLColabImages/lab3-fig2.png)\n","\n","-1, -2, -1, 0, 0, 0, 1, 2, 1 を使うと、水平線が得られます。\n","\n","![Detecting horizontal lines](https://storage.googleapis.com/laurencemoroney-blog.appspot.com/MLColabImages/lab3-fig3.png)\n","\n","違う値で試してみましょう！ "]},{"cell_type":"markdown","metadata":{"id":"xF0FPplsgHNh"},"source":["## Pooling\n","\n","畳み込みを使用するのと同様に、プーリングは特徴の検出に大きく役立ちます。目的は、検出された特徴をそのまま維持しながら、画像内の情報量を全体的に減らすことです。\n","\n","プーリングにはいくつかの異なるタイプがありますが、ここでは MAX プーリングと呼ばれるものを使用します。\n","\n"," ここでの考え方は、画像を繰り返し処理して、そのピクセルと、そのピクセルの右、下、右下ピクセルを見ていくことです。その中から最大のもの (これが MAX プーリングという名前の由来です) を取り出して新しい画像に読み込みます。このようにして、新しい画像は古い画像の 1/4 のサイズになります -- X と Y の寸法はこのプロセスによって半分になります。この圧縮にもかかわらず、画像の特徴が維持されていることがわかります。\n","\n","![Max Pooling](https://storage.googleapis.com/laurencemoroney-blog.appspot.com/MLColabImages/lab3-fig4.png)\n","\n","![CNN](https://jp.mathworks.com/help/deeplearning/ug/no_padding_no_strides.gif)\n","\n","このコードは、(2, 2)プーリングを表示します。これを実行して出力を見てみると、画像のサイズが元の1/4であるにもかかわらず、抽出された特徴が維持されていることがわかるでしょう!\n"]},{"cell_type":"code","metadata":{"id":"kDHjf-ehaBqm"},"source":["new_x = int(size_x/2)\n","new_y = int(size_y/2)\n","newImage = np.zeros((new_x, new_y))\n","for x in range(0, size_x, 2):\n","  for y in range(0, size_y, 2):\n","    pixels = []\n","    pixels.append(i_transformed[x, y])\n","    pixels.append(i_transformed[x+1, y])\n","    pixels.append(i_transformed[x, y+1])\n","    pixels.append(i_transformed[x+1, y+1])\n","    pixels.sort(reverse=True)\n","    newImage[int(x/2),int(y/2)] = pixels[0]\n","\n","# Plot the image. Note the size of the axes -- now 256 pixels instead of 512\n","plt.gray()\n","plt.grid(False)\n","plt.imshow(newImage)\n","#plt.axis('off')\n","plt.show()      \n","    \n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jZWdU6dVYQm-"},"source":["次では、Fashion MNISTニューラルネットワークに畳み込みを追加して、分類がより効率的に動作する（元画像のピクセルを利用するのではなく、特徴を利用して分類するため）ところを見てみましょう。"]}]}