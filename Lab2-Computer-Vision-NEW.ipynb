{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"12O-E7oySsv-d0XAkc3G6HZInNrUnxMyY","timestamp":1590545482665},{"file_id":"1UedqNyBEC4zoyrUkdEMxqi6XCptK4vvb","timestamp":1589364566180},{"file_id":"https://github.com/lmoroney/mlday-tokyo/blob/master/Lab2-Computer-Vision.ipynb","timestamp":1589251439967}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qnyTxjK_GbOD"},"source":["# Beyond Hello World, A Computer Vision Example\n","\n","\n","前回の演習では、自分が解決しようとしている問題を解決するためのニューラルネットワークを作成する方法を見ました。これは学習された動作の明示的な例を示していました。もちろん、この例では、機械学習を使ってXとYの関係を学習し、固定された値の集合に対してそれをすべての値に対して拡張するのではなく、関数Y=3x+1を直接書く方が簡単だったでしょうから、少しやりすぎでした。\n","\n","しかし、このようなルールを書くのがもっと難しいシナリオ、例えばコンピュータビジョンの問題ではどうでしょうか？10種類の異なるタイプの服を含むデータセットから学習して、異なる服のアイテムを認識するシナリオを見てみましょう。"]},{"cell_type":"markdown","metadata":{"id":"H41FYgtlHPjW"},"source":["## Start Coding\n","\n","\n","まずはTensorFlowのインポートから始めましょう"]},{"cell_type":"code","metadata":{"id":"q3KzJyjv3rnA"},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2sKswgmaMenc"},"source":["\n","\n","Fashion MNISTと呼ばれる共通のデータセットから服のアイテムを認識するためのニューラルネットワークを訓練します。このデータセットについての詳細は[こちら](https://github.com/zalandoresearch/fashion-mnist)を参照してください。\n","\n","このデータセットには、10種類のカテゴリに分類された7万点の衣類が含まれています。衣類の各アイテムは28x28のグレースケールの画像になっています。ここでいくつかの例を見ることができます。\n","\n","![alt text](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)"]},{"cell_type":"markdown","metadata":{"id":"n_n1U5do3u_F"},"source":["\n","\n","Fashion MNISTのデータは、tf.keras datasets APIで直接利用できます。読み込みは以下のように行います。"]},{"cell_type":"code","metadata":{"id":"PmxkHFpt31bM"},"source":["mnist = tf.keras.datasets.fashion_mnist"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GuoLQQBT4E-_"},"source":["\n","\n","このオブジェクトで load_data を呼び出すと、2つのリストの2つのセットが得られます。これらは、衣類のアイテムとそのラベルを含むグラフィックスのトレーニング値とテスト値になります。"]},{"cell_type":"code","metadata":{"id":"BTdRgExe4TRB"},"source":["(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rw395ROx4f5Q"},"source":["\n","\n","これらの値はどのように見えるでしょうか？トレーニング画像とトレーニングラベルを表示して見てみましょう...配列の異なるインデックスを表示したらどうなるでしょうか。例えばインデックス番号42ですが、これはインデックス番号が0のものとは異なるブーツの画像です。"]},{"cell_type":"code","metadata":{"id":"FPc9d3gJ3jWF"},"source":["import matplotlib.pyplot as plt\n","plt.imshow(training_images[0])\n","print(training_labels[0])\n","print(training_images[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3cbrdH225_nH"},"source":["\n","\n","また、数値の中のすべての値が0から255の間であることに気づくでしょう。ニューラルネットワークを学習する場合、様々な理由から、すべての値を0から1の間の値として扱う方が簡単です。そのことを、「**normalizing（正規化）**」と呼びます。幸運なことに、Pythonではループを作ることなく簡単に正規化することができます。方法は以下の通りです。"]},{"cell_type":"code","metadata":{"id":"kRH19pWs6ZDn"},"source":["training_images  = training_images / 255.0\n","test_images = test_images / 255.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3DkO0As46lRn"},"source":["\n","\n","さて、なぜ2つのセット（トレーニングとテスト）があるのか不思議に思うかもしれません。冒頭の部分でこれについて話したのを覚えていますか？このアイデアは、トレーニング用に1つのデータセット。もうひとつは、モデルがまだ見ていない別のものになります。これはデータを分類するのにどれだけ優れているかを確認するためです。一般性を確認するために、トレーニンで使用していないデータで試す必要があることは理解いただけると思います。\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dIn7S9gf62ie"},"source":["\n","\n","では、モデルを設計してみましょう。ここには新しい概念がかなりありますが、心配しないでください。"]},{"cell_type":"code","metadata":{"id":"7mAyndG3kVlK"},"source":["model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n","                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n","                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-lUcWaiX7MFj"},"source":["\n","\n","**Sequential**: ニューラルネットワークのレイヤーのシーケンスを定義します。\n","\n","**Flatten**: 以前、プリントアウトした画像が四角かったのを覚えていますか？平坦化は、その正方形を1次元のセットに変換します。\n","\n","**Dense**: ニューロンのレイヤーを追加します。\n","\n","ニューロンの各層には、**activation function（活性化関数）** が必要です。オプションはたくさんありますが、今のところは以下のものを使ってください。\n","\n","**Relu**は、「X>0ならXを返し、0なら0を返す」ということを意味します。結果として、0もしくはそれより大きな値を次のレイヤーに渡すだけです。\n","\n","**Softmax**は値のセットを受け取り、効果的に一番大きな値を選びます。例えば、最後のレイヤの出力が [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05] のようになっている場合、一番大きな値を探す手間を省き、[0,0,0,0,0,1,0,0,0,0] に変換してくれます。\n"]},{"cell_type":"markdown","metadata":{"id":"c8vbMCqb9Mh6"},"source":["\n","\n","次にやるべきことは、モデルが定義されたので、実際にそれを構築することです。先ほどと同じようにオプティマイザと損失関数を使ってコンパイルします -- そして、**model.fit **を呼び出してトレーニングを行います -- トレーニングデータから得られる推測値をラベルに一致するように学習させます -- つまり、トレーニングデータと実際のラベルの間の関係を把握させます。将来、学習データのようなデータがあれば、そのデータがどのように見えるかを予測することができます。"]},{"cell_type":"code","metadata":{"id":"BLMdl9aP8nQ0"},"source":["model.compile(optimizer = tf.keras.optimizers.Adam(),\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(training_images, training_labels, epochs=5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-JJMsvSB-1UY"},"source":["\n","\n","トレーニングが完了したら、最後のエポックの後に精度の値が表示されるはずです。0.9098のように見えるかもしれません。これは、ニューラルネットワークがトレーニングデータを分類するのに約91%の精度であることを示しています。つまり、画像とラベルの間のパターンマッチを計算して、91%の確率で機能していることになります。素晴らしいことではありませんが、5エポックの間だけ訓練されていて、かなり素早く行われたことを考えると、悪くはありません。\n","\n","それでは、まだ見ていないデータではどうでしょうか？そのためにテスト画像があります。model.evaluateを呼び出して、2つのセットを渡すことができます。試してみましょう。"]},{"cell_type":"code","metadata":{"id":"WzlqsEzX9s5P"},"source":["model.evaluate(test_images, test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6tki-Aro_Uax"},"source":["\n","\n","私の場合、約0.8838の精度が返されましたが、これは約88%の精度だったことを意味します。予想されていたように、これはおそらく、*見ていない*データでは、訓練されたデータと同じようにうまくいかないでしょう。このコースでは、これを改善する方法を見ていきます。\n","\n","さらに探求するには、以下の演習を試してみてください。"]},{"cell_type":"markdown","metadata":{"id":"htldZNWcIPSN"},"source":["# Exploration Exercises"]},{"cell_type":"markdown","metadata":{"id":"rquQqIx4AaGR"},"source":["###Exercise 1:\n","この最初の演習では、以下のコードを実行してください。テスト画像のそれぞれについて分類を行います。そして分類結果の最初のエントリを表示します。出力については、数字のリストとなります。これはなぜだと思いますか、また、これらの数字は何を表していると思いますか？"]},{"cell_type":"code","metadata":{"id":"RyEIki0z_hAD"},"source":["classifications = model.predict(test_images)\n","\n","print(classifications[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MdzqbQhRArzm"},"source":["ヒント: print(test_labels[0])を実行してみてください。 このリストがなぜこのように見えるのか理解できましたか？"]},{"cell_type":"code","metadata":{"id":"WnBGOrMiA1n5"},"source":["print(test_labels[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uUs7eqr7uSvs"},"source":["### このリストは何を表しているのでしょうか？\n","1.   無意味な10個のランダムな値\n","2.   コンピュータが作った最初の10分類\n","3.   10クラスそれぞれの確率\n"]},{"cell_type":"markdown","metadata":{"id":"wAbr92RTA67u"},"source":["####回答\n","正解は(3)です。"]},{"cell_type":"markdown","metadata":{"id":"CD4kC6TBu-69"},"source":["### このリストを見て、その商品がアンクルブーツであることがわかるのはなぜですか?\n","\n","\n","1.   その質問に答えるのに十分な情報がありません。\n","2.   リストの10番目の要素が最も大きく、アンクルブーツには9のラベルが付けられています。\n","3.   アンクルブーツはラベル9で、リストには0->9の要素があります。\n","\n"]},{"cell_type":"markdown","metadata":{"id":"I-haLncrva5L"},"source":["####回答\n","正解は(2)です。"]},{"cell_type":"markdown","metadata":{"id":"OgQSIfDSOWv6"},"source":["##Exercise 2: \n","それでは、あなたのモデルの層を見てみましょう。512個のニューロンを持つ全結合層の値を変えて実験してみてください。損失、トレーニング時間などについて変化が見られたでしょうか？それはなぜだと思いますか？\n","\n"]},{"cell_type":"code","metadata":{"id":"GSZSwV5UObQP"},"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","mnist = tf.keras.datasets.fashion_mnist\n","\n","(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n","\n","training_images = training_images/255.0\n","test_images = test_images/255.0\n","\n","model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n","                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n","\n","model.compile(optimizer = 'adam',\n","              loss = 'sparse_categorical_crossentropy')\n","\n","model.fit(training_images, training_labels, epochs=5)\n","\n","model.evaluate(test_images, test_labels)\n","\n","classifications = model.predict(test_images)\n","\n","print(classifications[0])\n","print(test_labels[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bOOEnHZFv5cS"},"source":["###質問1. ニューロンを1024個に増やした場合の影響は？\n","\n","1. トレーニングに時間がかかるが、より正確なトレーニングができる\n","2. トレーニングに時間がかかるが、精度には影響なし\n","3. トレーニング時間に変化がないが、より正確です。\n"]},{"cell_type":"markdown","metadata":{"id":"U73MUP2lwrI2"},"source":["####回答\n","正解は(1)です。"]},{"cell_type":"markdown","metadata":{"id":"WtWxK16hQxLN"},"source":["##Exercise 3: \n","\n","Flatten()レイヤーを削除するとどうなるか。なぜそうなると思いますか？\n","\n","データの形状に関するエラーが発生します。今は漠然としているように見えるかもしれませんが、ネットワークの最初のレイヤーはデータと同じ形状であるべきだという経験則を補強しています。今、私たちのデータは28x28の画像で、28のニューロンからなる28層のレイヤーは不可能なので、28,28を784x1に「平坦化」する方が理にかなっています。 自分たちで処理するためにすべてのコードを書かなくても、最初にFlatten()レイヤーを追加して、後で配列がモデルにロードされることで、自動的に平坦化されて処理を続けることができます。"]},{"cell_type":"code","metadata":{"id":"ExNxCwhcQ18S"},"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","mnist = tf.keras.datasets.fashion_mnist\n","\n","(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n","\n","training_images = training_images/255.0\n","test_images = test_images/255.0\n","\n","\n","model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n","                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n","\n","# This version has the 'flatten' removed. Replace the above with this one to see the error.\n","#model = tf.keras.models.Sequential([tf.keras.layers.Dense(64, activation=tf.nn.relu),\n","#                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n","\n","\n","model.compile(optimizer = 'adam',\n","              loss = 'sparse_categorical_crossentropy')\n","\n","model.fit(training_images, training_labels, epochs=5)\n","\n","model.evaluate(test_images, test_labels)\n","\n","classifications = model.predict(test_images)\n","\n","print(classifications[0])\n","print(test_labels[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VqoCR-ieSGDg"},"source":["##練習4. \n","\n","最終的な（出力される）レイヤーを考えてみましょう。なぜ10個もあるのでしょうか？10個とは異なる量を持っていたらどうなるでしょうか？例えば、5個にするとどうなるでしょうか。\n","\n","想定外の値を見つけるとすぐにエラーになります。もう一つの経験則 -- 最後の層のニューロンの数は、あなたが分類しているクラスの数と一致しなければなりません。この場合、0-9の数字なので、最終層には10個のニューロンがあるはずです。"]},{"cell_type":"code","metadata":{"id":"MMckVntcSPvo"},"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","mnist = tf.keras.datasets.fashion_mnist\n","\n","(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n","\n","training_images = training_images/255.0\n","test_images = test_images/255.0\n","\n","model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n","                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n","\n","# Replace the above model definiton with this one to see the network with 5 output layers\n","# And you'll see errors as a result!\n","# model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","#                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n","#                                    tf.keras.layers.Dense(5, activation=tf.nn.softmax)])\n","\n","model.compile(optimizer = 'adam',\n","              loss = 'sparse_categorical_crossentropy')\n","\n","model.fit(training_images, training_labels, epochs=5)\n","\n","model.evaluate(test_images, test_labels)\n","\n","classifications = model.predict(test_images)\n","\n","print(classifications[0])\n","print(test_labels[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-0lF5MuvSuZF"},"source":["##練習5. \n","\n","ネットワークにレイヤーを追加した場合の効果を考えてみましょう。512個のニューロンを持つ全結合層と10の最終層の間にもう1つのレイヤーを追加するとどうなるでしょうか。\n","\n","回答：大きな影響はありません -- これは比較的単純なデータだからです。はるかに複雑なデータ（次のレッスンで確認するカラー画像の花の分類等）では、多くの場合、追加のレイヤーが必要になります。"]},{"cell_type":"code","metadata":{"id":"b1YPa6UhS8Es"},"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","mnist = tf.keras.datasets.fashion_mnist\n","\n","(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n","\n","training_images = training_images/255.0\n","test_images = test_images/255.0\n","\n","model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n","                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n","                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n","\n","model.compile(optimizer = 'adam',\n","              loss = 'sparse_categorical_crossentropy')\n","\n","model.fit(training_images, training_labels, epochs=5)\n","\n","model.evaluate(test_images, test_labels)\n","\n","classifications = model.predict(test_images)\n","\n","print(classifications[0])\n","print(test_labels[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sE7PDe6LWAHb"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bql9fyaNUSFy"},"source":["#Exercise 6: \n","\n","エポック数を増減してトレーニングをした場合の影響を考えてみましょう。\n","\n","15エポックを試してみてください -- おそらく、5エポックのモデルよりもはるかに良い損失を持つモデルが得られるでしょう\n","30エポックを試してみてください -- 損失値の減少が止まったり、時には増加したりするのがわかるかもしれません。これは「過学習」と呼ばれる副作用です。これはニューラルネットワークをトレーニングするときには意識しておかなくてはならないものです。いずれにしても、損失が改善されないのであれば、時間をかけてトレーニングしても意味がないですよね。"]},{"cell_type":"code","metadata":{"id":"uE3esj9BURQe"},"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","mnist = tf.keras.datasets.fashion_mnist\n","\n","(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n","\n","training_images = training_images/255.0\n","test_images = test_images/255.0\n","\n","model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n","                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n","\n","model.compile(optimizer = 'adam',\n","              loss = 'sparse_categorical_crossentropy')\n","\n","model.fit(training_images, training_labels, epochs=30)\n","\n","model.evaluate(test_images, test_labels)\n","\n","classifications = model.predict(test_images)\n","\n","print(classifications[34])\n","print(test_labels[34])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HS3vVkOgCDGZ"},"source":["#Exercise 7: \n","\n","トレーニングの前に、データを正規化して、0-255の値から0-1の値にしました。これを削除した場合、どのような影響があるでしょうか？\n","以下のコードは、それを試すためのものです。なぜ異なる結果が得られると思いますか？"]},{"cell_type":"code","metadata":{"id":"JDqNAqrpCNg0"},"source":["import tensorflow as tf\n","print(tf.__version__)\n","mnist = tf.keras.datasets.fashion_mnist\n","(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n","# To experiment with removing normalization, comment out the following 2 lines\n","training_images=training_images/255.0\n","test_images=test_images/255.0\n","model = tf.keras.models.Sequential([\n","  tf.keras.layers.Flatten(),\n","  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n","  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n","])\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n","model.fit(training_images, training_labels, epochs=5)\n","model.evaluate(test_images, test_labels)\n","classifications = model.predict(test_images)\n","print(classifications[0])\n","print(test_labels[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E7W2PT66ZBHQ"},"source":["#Exercise 8: \n","\n","以前、エポックを追加してトレーニングをしていたときに、損失関数の出力が変わるかもしれないということがありました。トレーニングの完了を待つ間、「希望の精度に達したときにトレーニングを止められたらいいのに」と思ったかもしれません。たとえば、95%の精度がでれば十分な時にそれが、たった3エポックで実現できたとすると、残りのエポックが完了するまでどうして待たなくてはならないのかと思うかもしれません。どうすれば解決できるでしょうか。それを解決するためにコールバックがあります。実際に見てみましょう。"]},{"cell_type":"code","metadata":{"id":"pkaEHHgqZbYv"},"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs=None):\n","    if((logs['accuracy'] > 0.9)):\n","      print(\"\\nReached 90% accuracy so cancelling training!\")\n","      self.model.stop_training = True\n","\n","callbacks = myCallback()\n","mnist = tf.keras.datasets.fashion_mnist\n","(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n","training_images=training_images/255.0\n","test_images=test_images/255.0\n","model = tf.keras.models.Sequential([\n","  tf.keras.layers.Flatten(),\n","  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n","  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n","])\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])\n","\n","\n"],"execution_count":null,"outputs":[]}]}